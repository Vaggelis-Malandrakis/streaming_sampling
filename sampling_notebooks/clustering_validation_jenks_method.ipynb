{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b388cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from jenks import jenks\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46553b",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "path = '../dataset/data13to17Feb2018.csv'\n",
    "df = pd.read_csv(path, usecols=['Time', 'Source', 'Destination', 'Protocol', 'Length']).dropna()\n",
    "\n",
    "# keep only the columns that we want\n",
    "df = df[['Time', 'Length']]\n",
    "\n",
    "# transform time column to datetime object\n",
    "df['Time']= pd.to_datetime(df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428759a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to disregard the records which have as date 1970\n",
    "df['Year'] = df['Time'].dt.year\n",
    "df = df[df['Year'] > 1970]\n",
    "df = df[['Time', 'Length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how the dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a3518",
   "metadata": {},
   "source": [
    "## Get a slice of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliced_df = df[(df['Time'].dt.day == 13) & (df['Time'].dt.hour > 14) & (df['Time'].dt.hour < 16)]\n",
    "# sliced_df = sliced_df.iloc[800:10800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = df[0:180000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed637f4",
   "metadata": {},
   "source": [
    "#### Plot the sliced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bae749",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sliced_df['Time']\n",
    "y = sliced_df['Length']\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 5))\n",
    "locator = mdates.AutoDateLocator(minticks=10, maxticks=20)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axs.xaxis.set_major_locator(locator)\n",
    "axs.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "axs.plot(x, y, alpha = 1, linestyle = '-', linewidth = 0, marker = 'o', markersize = 3)\n",
    "\n",
    "plt.title('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f0283",
   "metadata": {},
   "source": [
    "## Find ideal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to help up assign clusters\n",
    "def put_to_cluster(value, cluster_limits):\n",
    "    cluster_index = 0\n",
    "    for i in range(len(cluster_limits)):\n",
    "        upper = cluster_limits[i]\n",
    "        if value <= upper:\n",
    "            return cluster_index\n",
    "        cluster_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c59ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_variance_fit(array, classes):\n",
    "    # get the break points\n",
    "    classes = jenks(array, classes)\n",
    "\n",
    "    # do the actual classification\n",
    "    classified = np.array([put_to_cluster(i, classes) for i in array])\n",
    "\n",
    "    # max value of zones\n",
    "    maxz = max(classified)\n",
    "\n",
    "    # nested list of zone indices\n",
    "    zone_indices = [[idx for idx, val in enumerate(classified) if zone + 1 == val] for zone in range(maxz)]\n",
    "\n",
    "    # sum of squared deviations from array mean\n",
    "    sdam = np.sum((array - array.mean()) ** 2)\n",
    "\n",
    "    # sorted polygon stats\n",
    "    array_sort = [np.array([array[index] for index in zone]) for zone in zone_indices]\n",
    "\n",
    "    # sum of squared deviations of class means\n",
    "    sdcm = sum([np.sum((classified - classified.mean()) ** 2) for classified in array_sort])\n",
    "\n",
    "    # goodness of variance fit\n",
    "    gvf = (sdam - sdcm) / sdam\n",
    "\n",
    "    return gvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ef4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvf = 0.0\n",
    "nclasses = 2\n",
    "X = sliced_df['Length'].to_numpy()\n",
    "while gvf < 0.90:\n",
    "    print('Current gvf: ', gvf, ' nclasses: ', nclasses)\n",
    "    gvf = goodness_of_variance_fit(X, nclasses)\n",
    "    nclasses += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500faf2",
   "metadata": {},
   "source": [
    "## Clustering of the initial dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25fab9",
   "metadata": {},
   "source": [
    "#### Calculate the cluster limits based on the jenks method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd067ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_limits = jenks(y, nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ab01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign records of the sliced dataset in clusters\n",
    "sliced_df['Bucket'] = sliced_df['Length'].apply(lambda x: put_to_cluster(x, cluster_limits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d411c0",
   "metadata": {},
   "source": [
    "#### Plot the sliced dataset with the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26993c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 5))\n",
    "locator = mdates.AutoDateLocator(minticks=10, maxticks=20)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axs.xaxis.set_major_locator(locator)\n",
    "axs.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "sliced_df.reset_index().groupby('Bucket').plot(x='Time', y='Length', ax=axs, alpha = 1, linestyle = '-', linewidth = 0, marker = 'o', markersize = 3)\n",
    "\n",
    "axs.get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532e61f",
   "metadata": {},
   "source": [
    "## Concise sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for sampling\n",
    "event_list = []\n",
    "for index, row in sliced_df.iterrows():\n",
    "    event_list.append(str(index) + ',' + str(row['Time']) + ',' + str(row['Length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ac9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concise_sampling(event):\n",
    "    N = len(event)\n",
    "    a = 1.1 # We increase T by 10%\n",
    "    max_size = N / 10\n",
    "\n",
    "    # 1/T = selection probability\n",
    "    T = 1\n",
    "\n",
    "    #// S = Concise Sample\n",
    "    S = {}\n",
    "    S_help = {}\n",
    "    S_help_real_index = {}\n",
    "    len_S = 0\n",
    "\n",
    "    for ev in event:\n",
    "        \n",
    "        real_idx, idx, val = ev.split(\",\")\n",
    "        \n",
    "        t_real_idx = int(real_idx)\n",
    "        t_idx = datetime.strptime(idx, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        t_val = float(val)\n",
    "\n",
    "        if np.random.random() < 1/T:\n",
    "            if t_val in S:\n",
    "                S[t_val] += 1\n",
    "                S_help[t_val].append(t_idx)\n",
    "                S_help_real_index[t_val].append(t_real_idx)\n",
    "            else:\n",
    "                S_help[t_val] = [t_idx]\n",
    "                S_help_real_index[t_val] = [t_real_idx]\n",
    "                S[t_val] = 1\n",
    "            len_S += 1\n",
    "\n",
    "    \n",
    "        # Deletion step, Adjust sample when it gets too large\n",
    "        \n",
    "        if len_S> max_size:\n",
    "            T_prime = a * T\n",
    "            \n",
    "            for s in S:\n",
    "                for _ in range(S[s]):\n",
    "                    if np.random.random() < 1 - T/T_prime:\n",
    "                        S[s] -= 1\n",
    "                        len_S -=1\n",
    "                        if len(S_help[s]) == 1:\n",
    "                            S_help[s].pop(0)\n",
    "                            S_help_real_index[s].pop(0)\n",
    "                        else:\n",
    "                            rnd_metric = np.random.randint(0,len(S_help[s])-1)\n",
    "                            S_help[s].pop(rnd_metric)\n",
    "                            S_help_real_index[s].pop(rnd_metric)\n",
    "            \n",
    "            T = T_prime\n",
    "    \n",
    "    real_idx_list = []\n",
    "    idx_list = []\n",
    "    res_list = []\n",
    "\n",
    "    for s in S:\n",
    "        if S[s] > 0:\n",
    "            for i in range(S[s]):\n",
    "                idx_list.append(S_help[s][i])\n",
    "                real_idx_list.append(S_help_real_index[s][i])\n",
    "                res_list.append(s)\n",
    "\n",
    "    return idx_list, res_list, real_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff70a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list, res_list, real_idx_list = concise_sampling(event_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a47eb",
   "metadata": {},
   "source": [
    "## Sampled Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263e3c5",
   "metadata": {},
   "source": [
    "#### Plot without clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82326fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 5))\n",
    "locator = mdates.AutoDateLocator(minticks=10, maxticks=20)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axs.xaxis.set_major_locator(locator)\n",
    "axs.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "axs.plot(idx_list, res_list, alpha = 1, linestyle = '-', linewidth = 0, marker = 'o', markersize = 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26fa29",
   "metadata": {},
   "source": [
    "### Add the information for the initial clusters C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the sliced dataset\n",
    "sampled_df = pd.DataFrame({'Time':idx_list, 'Length':res_list}, index=real_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8350c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_with_sliced_df = sampled_df.merge(sliced_df, how = 'left', left_index=True, right_index=True)\n",
    "sampled_with_sliced_df = sampled_with_sliced_df[['Time_x','Length_x', 'Bucket']]\n",
    "sampled_with_sliced_df.columns = ['Time', 'Length', 'C_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_with_sliced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 5))\n",
    "locator = mdates.AutoDateLocator(minticks=10, maxticks=20)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axs.xaxis.set_major_locator(locator)\n",
    "axs.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "sampled_with_sliced_df.reset_index().groupby('C_cluster').plot(x='Time', y='Length', ax=axs, alpha = 1, linestyle = '-', linewidth = 0, marker = 'o', markersize = 3)\n",
    "\n",
    "axs.get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd29c58",
   "metadata": {},
   "source": [
    "### Prodcuce the new clusters C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the cluster limits for the sliced dataset\n",
    "cluster_limits = jenks(res_list, nclasses)\n",
    "\n",
    "# apply the new clusters in the sliced dataset\n",
    "sampled_with_sliced_df['C_prime_cluster'] = sampled_with_sliced_df['Length'].apply(lambda x: put_to_cluster(x, cluster_limits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da166d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sampled dataset\n",
    "sampled_with_sliced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d19b45",
   "metadata": {},
   "source": [
    "## Plot the new clustering C' in the sliced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 5))\n",
    "locator = mdates.AutoDateLocator(minticks=10, maxticks=20)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axs.xaxis.set_major_locator(locator)\n",
    "axs.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "sampled_with_sliced_df.reset_index().groupby('C_prime_cluster').plot(x='Time', y='Length', ax=axs, alpha = 1, linestyle = '-', linewidth = 0, marker = 'o', markersize = 3)\n",
    "\n",
    "axs.get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1278c1",
   "metadata": {},
   "source": [
    "# Cluster Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b1627",
   "metadata": {},
   "source": [
    "S11 = pairs that are in the same cluster under C and C’\n",
    "\n",
    "S00 = pairs that are in different clusters under C and C’\n",
    "\n",
    "S10 = pairs that are in the same cluster under C but in different ones under C’\n",
    "\n",
    "S01 = pairs that are in different clusters under C but in the same under C’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_with_sliced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_with_sliced_df['key1'] = 0\n",
    "sampled_with_sliced_df['key2'] = 0\n",
    "sampled_with_sliced_df['index'] = sampled_with_sliced_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_joined_df = sampled_with_sliced_df.merge(sampled_with_sliced_df, left_on='key1', right_on='key2', how='outer')\n",
    "cross_joined_df = cross_joined_df[['index_x', 'index_y', 'C_cluster_x', 'C_prime_cluster_x', 'C_cluster_y', 'C_prime_cluster_y']]\n",
    "cross_joined_df = cross_joined_df[cross_joined_df['index_x'] != cross_joined_df['index_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2eef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n11 = len(cross_joined_df[(cross_joined_df['C_cluster_x'] == cross_joined_df['C_cluster_y']) \\\n",
    "                      & (cross_joined_df['C_prime_cluster_x'] == cross_joined_df['C_prime_cluster_y'])]) / 2\n",
    "\n",
    "n00 = len(cross_joined_df[(cross_joined_df['C_cluster_x'] != cross_joined_df['C_cluster_y']) \\\n",
    "                      & (cross_joined_df['C_prime_cluster_x'] != cross_joined_df['C_prime_cluster_y'])]) / 2\n",
    "\n",
    "n10 = len(cross_joined_df[(cross_joined_df['C_cluster_x'] == cross_joined_df['C_cluster_y']) \\\n",
    "                      & (cross_joined_df['C_prime_cluster_x'] != cross_joined_df['C_prime_cluster_y'])]) / 2\n",
    "\n",
    "n01 = len(cross_joined_df[(cross_joined_df['C_cluster_x'] != cross_joined_df['C_cluster_y']) \\\n",
    "                      & (cross_joined_df['C_prime_cluster_x'] == cross_joined_df['C_prime_cluster_y'])]) / 2\n",
    "\n",
    "n = len(sampled_with_sliced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143cef6",
   "metadata": {},
   "source": [
    "### Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a85d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = (2 * (n11 + n00)) / (n * (n - 1))\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd40f63",
   "metadata": {},
   "source": [
    "### Fowlkes–Mallows Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_index = n11 / np.sqrt((n11+n10)*(n11+n01))\n",
    "fm_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f173036",
   "metadata": {},
   "source": [
    "### Mirkin Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b22f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirkin_mettric = n*(n-1)*(1-rand_index)\n",
    "mirkin_mettric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e5637",
   "metadata": {},
   "source": [
    "### Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_index = n11 / (n11 + n10 + n01)\n",
    "jaccard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f39070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
